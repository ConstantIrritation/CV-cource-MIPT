{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32d088bc-f382-4231-aeef-d7036f0f4022",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10c5b9ef-13ba-47f0-9a2b-773e76933080",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa95662b-7ead-44f5-96dd-df340129d901",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab39712e-ed8d-4abc-8aa1-b6d5d4e5b079",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms.v2 as T\n",
    "from torch import nn\n",
    "import cv2\n",
    "from pylab import imshow\n",
    "import torch.nn.functional as F\n",
    "from numpy import array\n",
    "import random\n",
    "\n",
    "from torch.utils import data\n",
    "import PIL.Image\n",
    "import albumentations as A\n",
    "import albumentations.pytorch.transforms\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf183d10-92de-4910-bdcd-2a6303bee9b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7ca65c6-4f18-44f3-b6b2-e24709bdc63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(filename):\n",
    "    res = {}\n",
    "    with open(filename) as fhandle:\n",
    "        next(fhandle)\n",
    "        for line in fhandle:\n",
    "            parts = line.rstrip('\\n').split(',')\n",
    "            coords = array([float(x) for x in parts[1:]], dtype='float64')\n",
    "            res[parts[0]] = coords\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fefd124-3c94-4823-ae94-5c50e135b655",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_path = Path().absolute() / 'public_tests' / '00_test_img_input' / 'train' / 'images'\n",
    "train_gt_path = Path().absolute() / 'public_tests' / '00_test_img_input' / 'train' / 'gt.csv'\n",
    "assert train_images_path.exists(), train_images_path.absolute()\n",
    "assert train_gt_path.exists(), train_gt_path.absolute()\n",
    "\n",
    "train_gt = read_csv(train_gt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b1f6c53-9dac-4d5f-b155-c65098755bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCustomDataset(data.Dataset):\n",
    "    def __init__(self, mode, root_dir=train_images_path,\n",
    "                 train_fraction=0.8, split_seed=42, transform=None,):\n",
    "\n",
    "        paths = []\n",
    "        labels = []\n",
    "        rng = random.Random(split_seed)\n",
    "\n",
    "        cls_paths = sorted(glob.glob(f\"{root_dir}/*\"))\n",
    "        split = int(train_fraction * len(cls_paths))\n",
    "        rng.shuffle(cls_paths)\n",
    "\n",
    "        if mode == \"train\":\n",
    "            cls_paths = cls_paths[:split]\n",
    "        elif mode == \"valid\":\n",
    "            cls_paths = cls_paths[split:]\n",
    "        else:\n",
    "            raise RuntimeError(f\"Invalid mode: {mode!r}\")\n",
    "\n",
    "        paths.extend(cls_paths)\n",
    "        labels.extend(train_gt[sample.split('/')[-1]] for sample in cls_paths)\n",
    "\n",
    "        self._len = len(paths)\n",
    "        self._paths = paths\n",
    "        self._labels = np.array(labels)\n",
    "\n",
    "        if transform is None:\n",
    "            transform = DEFAULT_TRANSFORM\n",
    "        self._transform = transform\n",
    "        self._img_size = NETWORK_SIZE[0]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._paths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = self._paths[index]\n",
    "        label = self._labels[index]\n",
    "\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        tr = self._transform(image=image, keypoints=label.reshape(14, 2))\n",
    "        image = tr[\"image\"]\n",
    "        label = tr[\"keypoints\"].flatten()\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea20c0e3-4209-4682-b362-1d11203c2ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "NETWORK_SIZE = (224, 224)\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "common_transforms = [\n",
    "    A.Resize(*NETWORK_SIZE),\n",
    "    A.ToFloat(max_value=255),\n",
    "    A.Normalize(max_pixel_value=1.0, mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
    "    A.pytorch.transforms.ToTensorV2(),\n",
    "]\n",
    "\n",
    "MyTransform = A.Compose(common_transforms, keypoint_params=A.KeypointParams(format='xy', remove_invisible=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55fdcdc7-f2e2-4581-8908-7c264c7bde18",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = MyCustomDataset(mode=\"train\", transform=MyTransform)\n",
    "ds_valid = MyCustomDataset(mode=\"valid\", transform=MyTransform)\n",
    "\n",
    "dl_train = data.DataLoader(\n",
    "    ds_train,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=os.cpu_count(),\n",
    ")\n",
    "dl_valid = data.DataLoader(\n",
    "    ds_valid,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=os.cpu_count(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34333cd4-954d-4cfb-8c72-fe4b2a79b669",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "        )\n",
    "        self.identity = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "        )\n",
    "        \n",
    "        self.act = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.block(x)\n",
    "        out += self.identity(x)\n",
    "        return self.act(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0261726-8217-42e1-b8d7-5721e8016a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyResNetLike(nn.Sequential):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        self.bl1   = MyBlock(3, 64)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        self.bl2   = MyBlock(64, 128)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        self.bl3   = MyBlock(128, 256)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        self.bl4   = MyBlock(256, 512)\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.flatten = nn.Flatten(start_dim=1, end_dim=-1)\n",
    "\n",
    "        self.fc1 = nn.Linear(512 * (NETWORK_SIZE[0] // 16) ** 2, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "820e5873-4ad1-48b1-a777-cc30f03f4e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://stackoverflow.com/questions/71998978/early-stopping-in-pytorch\n",
    "class EarlyStopping:\n",
    "    def __init__(self, *, min_delta=1, patience=0):\n",
    "        self.min_delta = min_delta\n",
    "        self.patience = patience\n",
    "        self.best = float(\"inf\")\n",
    "        self.wait = 0\n",
    "        self.done = False\n",
    "\n",
    "    def step(self, current):\n",
    "        self.wait += 1\n",
    "\n",
    "        if current < self.best - self.min_delta:\n",
    "            self.best = current\n",
    "            self.wait = 0\n",
    "        elif self.wait >= self.patience:\n",
    "            self.done = True\n",
    "\n",
    "        return self.done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dec8df3a-4f81-415f-8354-d2383175beb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(num_epochs):\n",
    "    model = MyResNetLike(num_classes=28).to(DEVICE)\n",
    "    loss_fn = torch.nn.MSELoss().to(DEVICE)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3)\n",
    "    early_stopping = EarlyStopping(patience=10)\n",
    "\n",
    "    for e in range(num_epochs):\n",
    "\n",
    "        model = model.train()\n",
    "        train_loss = []\n",
    "        progress_train = tqdm(\n",
    "            total=len(dl_train),\n",
    "            desc=f\"Epoch {e}\",\n",
    "            leave=False,\n",
    "        )\n",
    "        for x_batch, y_batch in dl_train:\n",
    "            x_batch = x_batch.to(DEVICE)\n",
    "            y_batch = y_batch.to(DEVICE).float()\n",
    "\n",
    "            p_batch = model(x_batch)\n",
    "            loss = loss_fn(p_batch, y_batch)\n",
    "            train_loss.append(loss.detach())\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            progress_train.update()\n",
    "        \n",
    "        progress_train.close()\n",
    "\n",
    "        train_loss = torch.stack(train_loss).mean()\n",
    "        print(\n",
    "            f\"Epoch {e},\",\n",
    "            f\"train_loss: {train_loss.item():.8f}\",\n",
    "        )\n",
    "\n",
    "        model = model.eval()\n",
    "        valid_loss = []\n",
    "        progress_valid = tqdm(\n",
    "            total=len(dl_valid),\n",
    "            desc=f\"Epoch {e}\",\n",
    "            leave=False,\n",
    "        )\n",
    "        for x_batch, y_batch in dl_valid:\n",
    "            x_batch = x_batch.to(DEVICE)\n",
    "            y_batch = y_batch.to(DEVICE).float()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                p_batch = model(x_batch)\n",
    "\n",
    "            loss = loss_fn(p_batch, y_batch)\n",
    "            valid_loss.append(loss.detach())\n",
    "\n",
    "            progress_valid.update()\n",
    "        progress_valid.close()\n",
    "\n",
    "        valid_loss = torch.stack(valid_loss).mean()\n",
    "        print(\n",
    "            f\"Epoch {e},\",\n",
    "            f\"valid_loss: {valid_loss.item():.8f}\",\n",
    "        )\n",
    "        \n",
    "        scheduler.step(valid_loss)\n",
    "        if early_stopping.step(valid_loss):\n",
    "            break\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2371b453-4f28-4a62-bc53-e972804bbf89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = train(num_epochs=100)\n",
    "#took ~60 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d177984c-ebae-42eb-a836-b12132fc257f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images_path = Path().absolute() / 'public_tests' / '00_test_img_input' / 'test' / 'images'\n",
    "test_shapes_path = Path().absolute() / 'public_tests' / '00_test_img_gt' / 'img_shapes.csv'\n",
    "test_gt_path = Path().absolute() / 'public_tests' / '00_test_img_gt' / 'gt.csv'\n",
    "assert test_images_path.exists(), test_images_path.absolute()\n",
    "assert test_shapes_path.exists(), test_shapes_path.absolute()\n",
    "assert test_gt_path.exists(), test_gt_path.absolute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "47b33cbe-5481-41a6-b76b-f524d23afae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCustomTestDataset(data.Dataset):\n",
    "    def __init__(self, root_dir=test_images_path,\n",
    "                 transform=None):\n",
    "\n",
    "        paths = []\n",
    "        cls_paths = sorted(glob.glob(f\"{root_dir}/*\"))\n",
    "        paths.extend(cls_paths)\n",
    "\n",
    "        self._len = len(paths)\n",
    "        self._paths = paths\n",
    "        if transform is None:\n",
    "            transform = DEFAULT_TRANSFORM\n",
    "        self._transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._paths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = self._paths[index]\n",
    "\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        height, width = image.shape[:-1]\n",
    "        image = self._transform(image=image)[\"image\"]\n",
    "\n",
    "        return image, img_path.split('/')[-1], (width, height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "86f12a62-28e8-4f19-bffc-df704d039648",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test = MyCustomTestDataset(transform=MyTransform)\n",
    "\n",
    "dl_test = data.DataLoader(\n",
    "    ds_test,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=os.cpu_count(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1fa8b13a-0243-46ba-9b5b-3d5d3bdbbb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "points = []\n",
    "names = []\n",
    "\n",
    "def test(fitted_model):\n",
    "    model = fitted_model\n",
    "    model.eval()\n",
    "    model.to(DEVICE)\n",
    "\n",
    "    progress_test = tqdm(\n",
    "        total=len(dl_test),\n",
    "        leave=True,\n",
    "    )\n",
    "    with torch.no_grad():\n",
    "        for x_batch, x_path, x_shape in dl_test:\n",
    "            x_batch = x_batch.to(DEVICE)\n",
    "            \n",
    "            prediction = model(x_batch)\n",
    "            for i in range(len(x_batch)):\n",
    "                prediction_val = prediction[i].cpu().detach().numpy()\n",
    "                prediction_val[::2] *= x_shape[0][i].item() / NETWORK_SIZE[1]\n",
    "                prediction_val[1::2] *= x_shape[1][i].item() / NETWORK_SIZE[0]\n",
    "                points.append(prediction_val)\n",
    "                names.append(x_path[i])\n",
    "    \n",
    "            progress_test.update()\n",
    "        progress_test.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4497b087-75ce-4595-877e-7614577d5f6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03d95a2c6afd4a1f825b62d82820666f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f462fc34-d01c-41ea-b261-d40aebf85a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('output.csv', mode='w', newline='', encoding='utf-8') as file:\n",
    "    file.write('filename,x1,y1,x2,y2,x3,y3,x4,y4,x5,y5,x6,y6,x7,y7,x8,y8,x9,y9,x10,y10,x11,y11,x12,y12,x13,y13,x14,y14\\n')\n",
    "    for i in range(len(points)):\n",
    "        file.write(names[i] + ',' + ','.join([ str(j) for j in points[i] ]) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62735aca-50d8-40b3-8f60-03996033f9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_img_shapes(filename):\n",
    "    img_shapes = {}\n",
    "    with open(filename) as fhandle:\n",
    "        next(fhandle)\n",
    "        for line in fhandle:\n",
    "            parts = line.rstrip('\\n').split(',')\n",
    "            filename = parts[0]\n",
    "            n_rows, n_cols = map(int, parts[1:])\n",
    "            img_shapes[filename] = (n_rows, n_cols)\n",
    "    return img_shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f22f694a-c4f6-4c15-9840-a5c37ece6d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "detected = read_csv('output.csv')\n",
    "gt = read_csv(test_gt_path)\n",
    "img_shapes = read_img_shapes(test_shapes_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d988fed2-7479-4d55-9482-56c5b127720c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ok, error 4.8415\n"
     ]
    }
   ],
   "source": [
    "error = 0.0\n",
    "all_found = True\n",
    "for filename, gt_coords in gt.items():\n",
    "    if filename not in detected:\n",
    "        all_found = False\n",
    "        res = f'Error, keypoints for \"{filename}\" not found'\n",
    "        break\n",
    "\n",
    "    coords = detected[filename]\n",
    "    n_rows, n_cols = img_shapes[filename]\n",
    "\n",
    "    diff = (coords - gt_coords)\n",
    "    diff[::2] /= n_cols\n",
    "    diff[1::2] /= n_rows\n",
    "    diff *= 100\n",
    "    error += (diff ** 2).mean()\n",
    "error /= len(gt)\n",
    "\n",
    "if all_found:\n",
    "    res = f'Ok, error {error:.4f}'\n",
    "\n",
    "print(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
